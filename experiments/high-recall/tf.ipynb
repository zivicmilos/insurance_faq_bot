{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9d24fbe",
   "metadata": {},
   "source": [
    "# Term Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e962139",
   "metadata": {},
   "source": [
    "## Term Frequency with different distance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4f3fa95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "N_NEIGHBOURS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "db91f3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_performance(vectorizer: CountVectorizer, knn: NearestNeighbors, vectorized_questions: csr_matrix) -> float:\n",
    "    \"\"\"\n",
    "    Calculate performance of finding similar questions\n",
    "\n",
    "    :param vectorizer: CountVectorizer\n",
    "        term frequency vectorizer\n",
    "    :param knn: NearestNeighbors\n",
    "        K-nearest neighbors\n",
    "    :param vectorized_questions: csr_matrix\n",
    "        input questions transformed with count vectorizer\n",
    "    :return:\n",
    "        score (lesser is better)\n",
    "    \"\"\"\n",
    "    with open(\"../../data/test_questions_json.json\") as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "\n",
    "    test_questions = json_data[\"question\"]\n",
    "    original = json_data[\"original\"]\n",
    "\n",
    "    test_questions = vectorizer.transform(test_questions)\n",
    "    _, indices = knn.kneighbors(test_questions.toarray())\n",
    "\n",
    "    original = vectorizer.transform(original)\n",
    "    indices_original = np.where((vectorized_questions.toarray() == original.toarray()[:, None]).all(-1))[1]\n",
    "\n",
    "    rank = np.where(indices == indices_original[:, None])[1]\n",
    "    penalization = (indices_original.shape[0] - rank.shape[0]) * 2 * N_NEIGHBOURS\n",
    "    score = (rank.sum() + penalization) / indices_original.shape[0]\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "39137dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/insurance_qna_dataset.csv\", sep=\"\\t\")\n",
    "df.drop(columns=df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "vectorizer = CountVectorizer(lowercase=True)\n",
    "questions = np.unique(df.iloc[:, 0].to_numpy())\n",
    "vectorized_questions = vectorizer.fit_transform(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068caf3e",
   "metadata": {},
   "source": [
    "### Euclidean metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "15f88950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 78.09%\n"
     ]
    }
   ],
   "source": [
    "knn = NearestNeighbors(n_neighbors=N_NEIGHBOURS, metric=\"euclidean\").fit(vectorized_questions.toarray())\n",
    "\n",
    "score = check_performance(vectorizer, knn, vectorized_questions)\n",
    "print(f\"Score: {100 - score / (2 * N_NEIGHBOURS) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382791b8",
   "metadata": {},
   "source": [
    "### Manhattan (cityblock) metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "19f09537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 77.89%\n"
     ]
    }
   ],
   "source": [
    "knn = NearestNeighbors(n_neighbors=N_NEIGHBOURS, metric=\"cityblock\").fit(vectorized_questions.toarray())\n",
    "\n",
    "score = check_performance(vectorizer, knn, vectorized_questions)\n",
    "print(f\"Score: {100 - score / (2 * N_NEIGHBOURS) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36088f22",
   "metadata": {},
   "source": [
    "### Cosine metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "22a9135e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 79.48%\n"
     ]
    }
   ],
   "source": [
    "knn = NearestNeighbors(n_neighbors=N_NEIGHBOURS, metric=\"cosine\").fit(vectorized_questions.toarray())\n",
    "\n",
    "score = check_performance(vectorizer, knn, vectorized_questions)\n",
    "print(f\"Score: {100 - score / (2 * N_NEIGHBOURS) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca26794",
   "metadata": {},
   "source": [
    "## Comparison between different numbers of neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "182d74a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neighbours: 1 | Score: 45.00%\n",
      "Number of neighbours: 5 | Score: 55.00%\n",
      "Number of neighbours: 10 | Score: 61.83%\n",
      "Number of neighbours: 25 | Score: 69.07%\n",
      "Number of neighbours: 50 | Score: 73.43%\n",
      "Number of neighbours: 100 | Score: 79.48%\n",
      "Number of neighbours: 150 | Score: 82.63%\n",
      "Number of neighbours: 200 | Score: 83.77%\n",
      "Number of neighbours: 300 | Score: 84.48%\n",
      "Number of neighbours: 400 | Score: 87.17%\n",
      "Number of neighbours: 500 | Score: 88.67%\n",
      "Number of neighbours: 10000 | Score: 99.47%\n",
      "Number of neighbours: 16000 | Score: 99.67%\n"
     ]
    }
   ],
   "source": [
    "N_NEIGHBOURS_GRID = (1, 5, 10, 25, 50, 100, 150, 200, 300, 400, 500, 10000, 16000)\n",
    "for N_NEIGHBOURS in N_NEIGHBOURS_GRID:\n",
    "    knn = NearestNeighbors(n_neighbors=N_NEIGHBOURS, metric=\"cosine\").fit(vectorized_questions.toarray())\n",
    "\n",
    "    score = check_performance(vectorizer, knn, vectorized_questions)\n",
    "    print(f\"Number of neighbours: {N_NEIGHBOURS} | Score: {100 - score / (2 * N_NEIGHBOURS) * 100:.2f}%\")\n",
    "N_NEIGHBOURS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac5e8d4",
   "metadata": {},
   "source": [
    "## Term Frequency with N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ae8b978b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 78.88%\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(lowercase=True, ngram_range=(1, 2))\n",
    "\n",
    "questions = np.unique(df.iloc[:, 0].to_numpy())\n",
    "vectorized_questions = vectorizer.fit_transform(questions)\n",
    "\n",
    "knn = NearestNeighbors(n_neighbors=N_NEIGHBOURS, metric=\"cosine\").fit(vectorized_questions.toarray())\n",
    "\n",
    "score = check_performance(vectorizer, knn, vectorized_questions)\n",
    "print(f\"Score: {100 - score / (2 * N_NEIGHBOURS) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce0ff04",
   "metadata": {},
   "source": [
    "## Term Frequency with Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "242e446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_sentence(sentence: str) -> str:\n",
    "    \"\"\"\n",
    "    Lemmatize the input sentence and return processed sentence\n",
    "\n",
    "    :param sentence: str\n",
    "        sentence to be lemmatized\n",
    "    :return:\n",
    "        lemmatized sentence\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = word_tokenize(sentence)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return \" \".join(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "190daeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_performance(vectorizer: CountVectorizer, knn: NearestNeighbors, vectorized_questions: csr_matrix) -> float:\n",
    "    \"\"\"\n",
    "    Calculate performance of finding similar questions\n",
    "\n",
    "    :param vectorizer: CountVectorizer\n",
    "        term frequency vectorizer\n",
    "    :param knn: NearestNeighbors\n",
    "        K-nearest neighbors\n",
    "    :param vectorized_questions: csr_matrix\n",
    "        input questions transformed with count vectorizer\n",
    "    :return:\n",
    "        score (lesser is better)\n",
    "    \"\"\"\n",
    "    with open(\"../../data/test_questions_json.json\") as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "\n",
    "    test_questions = json_data[\"question\"]\n",
    "    original = json_data[\"original\"]\n",
    "\n",
    "    test_questions = np.asarray([lemmatize_sentence(test_question) for test_question in test_questions])\n",
    "    test_questions = vectorizer.transform(test_questions)\n",
    "    _, indices = knn.kneighbors(test_questions.toarray())\n",
    "\n",
    "    original = np.asarray([lemmatize_sentence(orig) for orig in original])\n",
    "    original = vectorizer.transform(original)\n",
    "    indices_original = np.where((vectorized_questions.toarray() == original.toarray()[:, None]).all(-1))[1]\n",
    "\n",
    "    rank = np.where(indices == indices_original[:, None])[1]\n",
    "    penalization = (indices_original.shape[0] - rank.shape[0]) * 2 * N_NEIGHBOURS\n",
    "    score = (rank.sum() + penalization) / indices_original.shape[0]\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "cc5c9766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 76.04%\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(lowercase=True, ngram_range=(1, 1))\n",
    "\n",
    "questions = np.unique(df.iloc[:, 0].to_numpy())\n",
    "questions = np.asarray([lemmatize_sentence(question) for question in questions])\n",
    "vectorized_questions = vectorizer.fit_transform(questions)\n",
    "\n",
    "knn = NearestNeighbors(n_neighbors=N_NEIGHBOURS, metric=\"cosine\").fit(vectorized_questions.toarray())\n",
    "\n",
    "score = check_performance(vectorizer, knn, vectorized_questions)\n",
    "print(f\"Score: {100 - score / (2 * N_NEIGHBOURS) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34148843",
   "metadata": {},
   "source": [
    "## Term Frequency with Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8d6112da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_sentence(sentence: str) -> str:\n",
    "    \"\"\"\n",
    "    Stem the input sentence and return processed sentence\n",
    "\n",
    "    :param sentence: str\n",
    "        sentence to be stemmed\n",
    "    :return:\n",
    "        stemmed sentence\n",
    "    \"\"\"\n",
    "    stemmer = PorterStemmer()  # TODO: try other stemmer types\n",
    "    tokens = word_tokenize(sentence)\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return \" \".join(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "068ba5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_performance(vectorizer: CountVectorizer, knn: NearestNeighbors, vectorized_questions: csr_matrix) -> float:\n",
    "    \"\"\"\n",
    "    Calculate performance of finding similar questions\n",
    "\n",
    "    :param vectorizer: CountVectorizer\n",
    "        term frequency vectorizer\n",
    "    :param knn: NearestNeighbors\n",
    "        K-nearest neighbors\n",
    "    :param vectorized_questions: csr_matrix\n",
    "        input questions transformed with count vectorizer\n",
    "    :return:\n",
    "        score (lesser is better)\n",
    "    \"\"\"\n",
    "    with open(\"../../data/test_questions_json.json\") as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "\n",
    "    test_questions = json_data[\"question\"]\n",
    "    original = json_data[\"original\"]\n",
    "\n",
    "    test_questions = np.asarray([stem_sentence(test_question) for test_question in test_questions])\n",
    "    test_questions = vectorizer.transform(test_questions)\n",
    "    _, indices = knn.kneighbors(test_questions.toarray())\n",
    "\n",
    "    original = np.asarray([stem_sentence(orig) for orig in original])\n",
    "    original = vectorizer.transform(original)\n",
    "    indices_original = np.where((vectorized_questions.toarray() == original.toarray()[:, None]).all(-1))[1]\n",
    "\n",
    "    rank = np.where(indices == indices_original[:, None])[1]\n",
    "    penalization = (indices_original.shape[0] - rank.shape[0]) * 2 * N_NEIGHBOURS\n",
    "    score = (rank.sum() + penalization) / indices_original.shape[0]\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "855e96aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 82.58%\n"
     ]
    }
   ],
   "source": [
    "questions = np.unique(df.iloc[:, 0].to_numpy())\n",
    "questions = np.asarray([stem_sentence(question) for question in questions])\n",
    "vectorized_questions = vectorizer.fit_transform(questions)\n",
    "\n",
    "knn = NearestNeighbors(n_neighbors=N_NEIGHBOURS, metric=\"cosine\").fit(vectorized_questions.toarray())\n",
    "\n",
    "score = check_performance(vectorizer, knn, vectorized_questions)\n",
    "print(f\"Score: {100 - score / (2 * N_NEIGHBOURS) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c00d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:synechron] *",
   "language": "python",
   "name": "conda-env-synechron-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
